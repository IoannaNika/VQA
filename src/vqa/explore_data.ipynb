{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amplicon reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"minimap2 -ax map-hifi data/data/SARS-CoV-2-NC_045513.fa data/data/real_data/trimmed_09_0.fastq > aln.sam\")\n",
    "os.system(\"samtools view -@ n -Sb -o aln.bam aln.sam\")\n",
    "os.system(\"samtools sort -@ n -o aln.sorted.bam aln.bam\")\n",
    "os.system(\"samtools index aln.sorted.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce bed file for the amplicon reads\n",
    "os.system(\"bedtools bamtobed -i aln.sorted.bam > aln.sorted.bed\")\n",
    "\n",
    "# calculate the distribution of the read lengths\n",
    "df = pd.read_csv(\"aln.sorted.bed\", sep=\"\\t\", header=None)\n",
    "df[\"length\"] = df[2] - df[1]\n",
    "print(df[\"length\"].describe())\n",
    "\n",
    "# plot the distribution of the read lengths\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.hist(df[\"length\"], bins=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the read lengths\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df[\"length\"], bins=100)\n",
    "\n",
    "sns.histplot(df[\"length\"], bins=100)\n",
    "# save the plot\n",
    "plt.savefig(\"amplicon_read_length_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ONT reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"minimap2 -ax map-ont data/data/SARS-CoV-2-NC_045513.fa data/data/hcov_global_2023-11-16_09-28/split_fasta/A/simulated_reads/EPI_ISL_408480/EPI_ISL_408480_0001.fastq > aln_ont.sam\")\n",
    "os.system(\"samtools view -@ n -Sb -o aln_ont.bam aln_ont.sam\")\n",
    "os.system(\"samtools sort -@ n -o aln_ont.sorted.bam aln_ont.bam\")\n",
    "os.system(\"samtools index aln_ont.sorted.bam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify reads from the same genome that overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group reads that overlap given a bam file\n",
    "os.system(\"bedtools bamtobed -i aln_ont.bam > aln_ont.bed\")\n",
    "os.system(\"bedtools sort -i aln_ont.bed > aln_ont.sorted.bed\")\n",
    "\n",
    "# read in the bed file\n",
    "bed = pd.read_csv(\"aln_ont.sorted.bed\", sep=\"\\t\", header=None)\n",
    "bed.columns = [\"ref\", \"start\", \"end\", \"read_name\", \"score\", \"strand\"]\n",
    "\n",
    "\n",
    "# create a dictionary of read names and the reads they overlap with\n",
    "read_dict = {}\n",
    "\n",
    "for i in range(len(bed)):\n",
    "    for j in range(len(bed)):\n",
    "        if bed.iloc[i, 3] != bed.iloc[j, 3]:\n",
    "            # start_i < end_j  and end_i > start_j\n",
    "            if bed.iloc[i, 1] < bed.iloc[j, 2] and bed.iloc[i, 2] > bed.iloc[j, 1]:\n",
    "                if bed.iloc[i, 3] in read_dict:\n",
    "                    read_dict[bed.iloc[i, 3]].add(bed.iloc[j, 3])\n",
    "                else:\n",
    "                    read_dict[bed.iloc[i, 3]] = {bed.iloc[j, 3]}\n",
    "\n",
    "\n",
    "\n",
    "print(read_dict.keys())\n",
    "print(read_dict[\"EPI_ISL_4084801_23\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the reads from different genomes that overlap with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_file_1 = pd.read_csv(\"aln_ont.sorted.bed\", sep=\"\\t\", header=None)\n",
    "bed_file_2 = pd.read_csv(\"aln_ont.sorted.bed\", sep=\"\\t\", header=None)\n",
    "\n",
    "bed_file_1.columns = [\"ref\", \"start\", \"end\", \"read_name\", \"score\", \"strand\"]\n",
    "bed_file_2.columns = [\"ref\", \"start\", \"end\", \"read_name\", \"score\", \"strand\"]\n",
    "\n",
    "# create a dictionary of read names and the reads they overlap with\n",
    "\n",
    "read_dict = {}\n",
    "\n",
    "for i in range(len(bed_file_1)):\n",
    "    for j in range(len(bed_file_2)):\n",
    "            # start_i < end_j  and end_i > start_j\n",
    "            if bed_file_1.iloc[i, 1] < bed_file_2.iloc[j, 2] and bed_file_1.iloc[i, 2] > bed_file_2.iloc[j, 1]:\n",
    "                if bed_file_1.iloc[i, 3] in read_dict:\n",
    "                    read_dict[bed_file_1.iloc[i, 3]].add(bed_file_2.iloc[j, 3])\n",
    "                else:\n",
    "                    read_dict[bed_file_1.iloc[i, 3]] = {bed_file_2.iloc[j, 3]}\n",
    "\n",
    "# print(read_dict.keys())\n",
    "print(read_dict[\"EPI_ISL_4084801_23\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distribution of the read lengths for ont reads\n",
    "df = pd.read_csv(\"aln_ont.sorted.bed\", sep=\"\\t\", header=None)\n",
    "df[\"length\"] = df[2] - df[1]\n",
    "print(df[\"length\"].describe())\n",
    "\n",
    "# plot the distribution of the read lengths\n",
    "sns.set()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df[\"length\"], bins=100)\n",
    "# save the plot\n",
    "plt.savefig(\"ont_read_length_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_nr = \"data/data/hcov_global_2023-11-16_09-28/metadata.tsv\"\n",
    "metadata = pd.read_csv(metadata_nr, sep=\"\\t\")\n",
    "\n",
    "pango_lineage = metadata[\"pango_lineage\"].value_counts()\n",
    "GISAID_clade = metadata[\"GISAID_clade\"].value_counts()\n",
    "\n",
    "# pie plot of the pango lineage\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pie(pango_lineage, labels=pango_lineage.index, autopct='%1.1f%%')\n",
    "plt.title(\"Pango lineage\")\n",
    "plt.show()\n",
    "\n",
    "# pie plot of the GISAID clade\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.pie(GISAID_clade, labels=GISAID_clade.index, autopct='%1.1f%%')\n",
    "plt.title(\"GISAID clade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next regions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the the two metadata files contain any common strains\n",
    "metadata_nr_1 = \"data/data/hcov_global_2022-08-26_05-12/hcov_global.tsv\"\n",
    "metadata_nr_2 = \"data/data/hcov_global_2023-11-16_09-28/metadata.tsv\"\n",
    "\n",
    "metadata_1 = pd.read_csv(metadata_nr_1, sep=\"\\t\")\n",
    "metadata_2 = pd.read_csv(metadata_nr_2, sep=\"\\t\")\n",
    "\n",
    "# check if the the two metadata files contain any common strains\n",
    "print(set(metadata_1[\"strain\"]).intersection(set(metadata_2[\"strain\"])))\n",
    "print(len(set(metadata_1[\"strain\"]).intersection(set(metadata_2[\"strain\"]))))\n",
    "\n",
    "# remove the common strains from the 2022 metadata\n",
    "metadata_1 = metadata_1[~metadata_1[\"strain\"].isin(set(metadata_1[\"strain\"]).intersection(set(metadata_2[\"strain\"])))]\n",
    "# remove reads that their lineage is not contained in metadata_2\n",
    "metadata_1 = metadata_1[metadata_1[\"pango_lineage\"].isin(set(metadata_2[\"pango_lineage\"]))]\n",
    "metadata_1.to_csv(\"data/data/hcov_global_2022-08-26_05-12/metadata.tsv\", sep=\"\\t\", index=False)\n",
    "# parse the fasta file\n",
    "records = SeqIO.parse(\"data/data/hcov_global_2022-08-26_05-12/hcov_global.fasta\", \"fasta\")\n",
    "\n",
    "# clean contents of the sequences.fasta file\n",
    "open(\"data/data/hcov_global_2022-08-26_05-12/sequences.fasta\", \"w\").close()\n",
    "cnt = 0\n",
    "cnt2 = 0\n",
    "for record in records:\n",
    "    cnt2 += 1\n",
    "    if record.id in set(metadata_1[\"strain\"]):\n",
    "        with open(\"data/data/hcov_global_2022-08-26_05-12/sequences.fasta\", \"a\") as f:\n",
    "            f.write(\">\" + record.id + \"\\n\")\n",
    "            f.write(str(record.seq) + \"\\n\")    \n",
    "            cnt += 1\n",
    "   \n",
    "print(cnt, len(set(metadata_1[\"strain\"])),cnt2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
